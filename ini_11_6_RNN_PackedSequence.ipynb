{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ0/Q0D6han7Yh4YciZNmY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ililililililililililililililil/INI/blob/ini_pytorch/ini_11_6_RNN_PackedSequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#시퀀스 데이터: 텍스트 데이터, 오디오 데이터\n",
        "#시퀀스 데이터는 길이가 미정인 경우가 많음\n",
        "\n",
        "#사이즈가 다른 시퀀스 데이터\n",
        "#1. 패딩 방법으로 남는 부분을 <pad>로 한다. 계산하지 않아도 될 뒷부분을 계산\n",
        "#2. 길이에 대한 정보를 저장한다. 길이 내림차순으로 정렬되어야 파이토치에서 가능"
      ],
      "metadata": {
        "id": "TEdvIgRr78Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ubpSPwbJ7IW8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random word from random word generator\n",
        "data = ['hello world',\n",
        "        'midnight',\n",
        "        'calculation',\n",
        "        'path',\n",
        "        'short circuit']\n",
        "\n",
        "# Make dictionary\n",
        "char_set = ['<pad>'] + list(set(char for seq in data for char in seq)) # Get all characters and include pad token\n",
        "char2idx = {char: idx for idx, char in enumerate(char_set)} # Constuct character to index dictionary\n",
        "print('char_set:', char_set)\n",
        "print('char_set length:', len(char_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF2Jklp47Tx5",
        "outputId": "4039a9fe-7440-4205-91d1-18cd20f0a510"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "char_set: ['<pad>', 'p', 's', 'n', 'h', 'u', 'a', 'c', 'g', 'l', 'e', 'm', 'd', 'w', 't', ' ', 'r', 'o', 'i']\n",
            "char_set length: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert character to index and make list of tensors\n",
        "X = [torch.LongTensor([char2idx[char] for char in seq]) for seq in data]\n",
        "\n",
        "# Check converted result\n",
        "for sequence in X:\n",
        "    print(sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY9ZssCz7WU3",
        "outputId": "a757c37c-e6be-4cb2-9f04-ad8cf2fe7c42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4, 10,  9,  9, 17, 15, 13, 17, 16,  9, 12])\n",
            "tensor([11, 18, 12,  3, 18,  8,  4, 14])\n",
            "tensor([ 7,  6,  9,  7,  5,  9,  6, 14, 18, 17,  3])\n",
            "tensor([ 1,  6, 14,  4])\n",
            "tensor([ 2,  4, 17, 16, 14, 15,  7, 18, 16,  7,  5, 18, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make length tensor (will be used later in 'pack_padded_sequence' function)\n",
        "lengths = [len(seq) for seq in X]\n",
        "print('lengths:', lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8437BI1e7YEu",
        "outputId": "27b1f51e-0c6e-4ca0-d85d-6abdd23d2c87"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengths: [11, 8, 11, 4, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a Tensor of shape (Batch x Maximum_Sequence_Length)\n",
        "padded_sequence = pad_sequence(X, batch_first=True) # X is now padded sequence\n",
        "print(padded_sequence)\n",
        "print(padded_sequence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14MQ636l7avr",
        "outputId": "26bb8305-ef90-4c46-cfa9-27841ae9183f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4, 10,  9,  9, 17, 15, 13, 17, 16,  9, 12,  0,  0],\n",
            "        [11, 18, 12,  3, 18,  8,  4, 14,  0,  0,  0,  0,  0],\n",
            "        [ 7,  6,  9,  7,  5,  9,  6, 14, 18, 17,  3,  0,  0],\n",
            "        [ 1,  6, 14,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 2,  4, 17, 16, 14, 15,  7, 18, 16,  7,  5, 18, 14]])\n",
            "torch.Size([5, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by descending lengths\n",
        "sorted_idx = sorted(range(len(lengths)), key=lengths.__getitem__, reverse=True)\n",
        "sorted_X = [X[idx] for idx in sorted_idx]\n",
        "\n",
        "# Check converted result\n",
        "for sequence in sorted_X:\n",
        "    print(sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx4VadJN7dw9",
        "outputId": "a81e9af6-3e8a-418a-b45f-9e5f97cd022c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2,  4, 17, 16, 14, 15,  7, 18, 16,  7,  5, 18, 14])\n",
            "tensor([ 4, 10,  9,  9, 17, 15, 13, 17, 16,  9, 12])\n",
            "tensor([ 7,  6,  9,  7,  5,  9,  6, 14, 18, 17,  3])\n",
            "tensor([11, 18, 12,  3, 18,  8,  4, 14])\n",
            "tensor([ 1,  6, 14,  4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "packed_sequence = pack_sequence(sorted_X)\n",
        "print(packed_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9smHc8it7faE",
        "outputId": "8908432f-8c52-4589-8d70-ff61c39d04c4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PackedSequence(data=tensor([ 2,  4,  7, 11,  1,  4, 10,  6, 18,  6, 17,  9,  9, 12, 14, 16,  9,  7,\n",
            "         3,  4, 14, 17,  5, 18, 15, 15,  9,  8,  7, 13,  6,  4, 18, 17, 14, 14,\n",
            "        16, 16, 18,  7,  9, 17,  5, 12,  3, 18, 14]), batch_sizes=tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1]), sorted_indices=None, unsorted_indices=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot embedding using PaddedSequence\n",
        "eye = torch.eye(len(char_set)) # Identity matrix of shape (len(char_set), len(char_set))\n",
        "embedded_tensor = eye[padded_sequence]\n",
        "print(embedded_tensor.shape) # shape: (Batch_size, max_sequence_length, number_of_input_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3OLRA257idx",
        "outputId": "0bdc7658-fe27-4a07-a448-347d7c2d3f81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 13, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot embedding using PackedSequence\n",
        "embedded_packed_seq = pack_sequence([eye[X[idx]] for idx in sorted_idx])\n",
        "print(embedded_packed_seq.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBzzpCRG7kRc",
        "outputId": "bb8c4ba9-2764-4e26-e3ae-5050c98998f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([47, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# declare RNN\n",
        "rnn = torch.nn.RNN(input_size=len(char_set), hidden_size=30, batch_first=True)"
      ],
      "metadata": {
        "id": "-3x7mmBR7mFI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_output, hidden = rnn(embedded_tensor)\n",
        "print(rnn_output.shape) # shape: (batch_size, max_seq_length, hidden_size)\n",
        "print(hidden.shape)     # shape: (num_layers * num_directions, batch_size, hidden_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SVv2NCp7pd8",
        "outputId": "bf0d8424-248c-468d-a9c5-1175ef80bf8f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 13, 30])\n",
            "torch.Size([1, 5, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_output, hidden = rnn(embedded_packed_seq)\n",
        "print(rnn_output.data.shape)\n",
        "print(hidden.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZI2YQT77rZN",
        "outputId": "3764e5ff-fe9d-4be4-a423-4306552673c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([47, 30])\n",
            "torch.Size([1, 5, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unpacked_sequence, seq_lengths = pad_packed_sequence(embedded_packed_seq, batch_first=True)\n",
        "print(unpacked_sequence.shape)\n",
        "print(seq_lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5ZMWR6i7ttm",
        "outputId": "8f82a6b1-f699-41e7-9bda-bf45aeb94369"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 13, 19])\n",
            "tensor([13, 11, 11,  8,  4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_padded_sequence = eye[pad_sequence(sorted_X, batch_first=True)]\n",
        "print(embedded_padded_sequence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zITobHCA7vwP",
        "outputId": "4470dd26-8dd9-4d66-a672-cd7155619800"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 13, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_lengths = sorted(lengths, reverse=True)\n",
        "new_packed_sequence = pack_padded_sequence(embedded_padded_sequence, sorted_lengths, batch_first=True)\n",
        "print(new_packed_sequence.data.shape)\n",
        "print(new_packed_sequence.batch_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh0yNLY47yBR",
        "outputId": "380b8933-c3c4-4596-f8f4-ca5ee685f1cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([47, 19])\n",
            "tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f-UuMITX70CK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}