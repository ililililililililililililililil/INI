{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4E7ufltHB20rCE2oT6Rot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ililililililililililililililil/INI/blob/ini_pytorch/ini_9_3_Dropoutipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wK-0yLieSfFm"
      },
      "outputs": [],
      "source": [
        "#Overfitting: 과적합\n",
        "#train에서는 잘 훈련되어 있지만 test에서는 다른 데이터가 들어오기 때문에 오히려 에러가 증가할 수 있다\n",
        "\n",
        "#Overfitting 해결 -> Dropout\n",
        "#학습을 진행하면서 각 노드를 무작위로 껐다 켰다를 반복한다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 10 MNIST and softmax\n",
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import random"
      ],
      "metadata": {
        "id": "PnuJAJUWVUJo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "hnFE7hmPVW2x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "drop_prob = 0.3"
      ],
      "metadata": {
        "id": "MLbRGBdyVYoF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njjt-3z2VZ3X",
        "outputId": "3399bb62-4d6d-4d8f-ef0f-07df1ec93c1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 317425149.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 32519649.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 138965406.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4542/4542 [00:00<00:00, 4350429.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)"
      ],
      "metadata": {
        "id": "5cboqvYDVb7N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn layers\n",
        "linear1 = torch.nn.Linear(784, 512, bias=True)\n",
        "linear2 = torch.nn.Linear(512, 512, bias=True)\n",
        "linear3 = torch.nn.Linear(512, 512, bias=True)\n",
        "linear4 = torch.nn.Linear(512, 512, bias=True)\n",
        "linear5 = torch.nn.Linear(512, 10, bias=True)\n",
        "relu = torch.nn.ReLU()\n",
        "dropout = torch.nn.Dropout(p=drop_prob)"
      ],
      "metadata": {
        "id": "wcGAOU9IVfVd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xavier initialization\n",
        "torch.nn.init.xavier_uniform_(linear1.weight)\n",
        "torch.nn.init.xavier_uniform_(linear2.weight)\n",
        "torch.nn.init.xavier_uniform_(linear3.weight)\n",
        "torch.nn.init.xavier_uniform_(linear4.weight)\n",
        "torch.nn.init.xavier_uniform_(linear5.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx0RkmitVgfC",
        "outputId": "fb5f79db-2657-4935-eb73-3848f28fd3d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0565,  0.0423, -0.0155,  ...,  0.1012,  0.0459, -0.0191],\n",
              "        [ 0.0772,  0.0452, -0.0638,  ...,  0.0476, -0.0638,  0.0528],\n",
              "        [ 0.0311, -0.1023, -0.0701,  ...,  0.0412, -0.1004,  0.0738],\n",
              "        ...,\n",
              "        [ 0.0334,  0.0187, -0.1021,  ...,  0.0280, -0.0583, -0.1018],\n",
              "        [-0.0506, -0.0939, -0.0467,  ..., -0.0554, -0.0325,  0.0640],\n",
              "        [-0.0183, -0.0123,  0.1025,  ..., -0.0214,  0.0220, -0.0741]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model = torch.nn.Sequential(linear1, relu, dropout,\n",
        "                            linear2, relu, dropout,\n",
        "                            linear3, relu, dropout,\n",
        "                            linear4, relu, dropout,\n",
        "                            linear5).to(device)"
      ],
      "metadata": {
        "id": "6hZfIef4Vh5i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "0Wddxy4GVmE0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = len(data_loader)\n",
        "model.train()    # set the model to train mode (dropout=True)\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning finished')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXkv5V4_VnNF",
        "outputId": "d4c1117d-61d1-4324-9eca-47f5723cbc0f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 cost = 0.310621142\n",
            "Epoch: 0002 cost = 0.146159276\n",
            "Epoch: 0003 cost = 0.111172289\n",
            "Epoch: 0004 cost = 0.094859935\n",
            "Epoch: 0005 cost = 0.082409069\n",
            "Epoch: 0006 cost = 0.072757378\n",
            "Epoch: 0007 cost = 0.071835004\n",
            "Epoch: 0008 cost = 0.059738025\n",
            "Epoch: 0009 cost = 0.059085678\n",
            "Epoch: 0010 cost = 0.055539340\n",
            "Epoch: 0011 cost = 0.051415320\n",
            "Epoch: 0012 cost = 0.047818515\n",
            "Epoch: 0013 cost = 0.045675199\n",
            "Epoch: 0014 cost = 0.046652373\n",
            "Epoch: 0015 cost = 0.046102792\n",
            "Learning finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model and check accuracy\n",
        "with torch.no_grad():\n",
        "    model.eval()    # set the model to evaluation mode (dropout=False)\n",
        "\n",
        "    # Test the model using test sets\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())\n",
        "\n",
        "    # Get one and predict\n",
        "    r = random.randint(0, len(mnist_test) - 1)\n",
        "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
        "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
        "\n",
        "    print('Label: ', Y_single_data.item())\n",
        "    single_prediction = model(X_single_data)\n",
        "    print('Prediction: ', torch.argmax(single_prediction, 1).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDipYNkDVo2t",
        "outputId": "7e5ad736-2969-4507-d741-c326aa5ef18d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.980400025844574\n",
            "Label:  8\n",
            "Prediction:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cbVslVPMVrUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}